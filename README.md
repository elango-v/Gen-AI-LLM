# Gen-AI-LLM

# Local Chat box with oLLama2

1. ollama run llama2
2. streamlit run lang-chain-llm.py

# RAG with local Ollama3.2
1. Download llama3.2 to local
    ollama pull llama3.2:3b-instruct-fp16
2. Rul ollama3.2
   ollama run llama3.2:3b-instruct-fp16
     
